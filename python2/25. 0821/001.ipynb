{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f161683f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://example.com/contact', 'https://example.com/article/3', 'https://example.com/about', 'https://example.com/home', 'https://example.com/article/1', 'https://example.com/article/2']\n",
      "https://example.com/contact : example.com이 포함됨\n",
      "https://example.com/article/3 : example.com이 포함됨\n",
      "https://example.com/about : example.com이 포함됨\n",
      "https://example.com/home : example.com이 포함됨\n",
      "https://example.com/article/1 : example.com이 포함됨\n",
      "https://example.com/article/2 : example.com이 포함됨\n"
     ]
    }
   ],
   "source": [
    "# 네비게이션 링크 추출 --> 리스트로\n",
    "# 글 링크 추출 --> 리스트로\n",
    "# 최종 중복링크 제거된 리스트 확보 목적\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"http://ssacademy.dothome.co.kr/01.html\"\n",
    "response = requests.get(url)\n",
    "response.encoding = 'utf-8'\n",
    "html = response.text\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "navi = soup.select('a.nav-link')\n",
    "\n",
    "article = soup.select('a.article-link')\n",
    "\n",
    "full_list = list(set([a['href'] for a in navi] + [a['href'] for a in article]))\n",
    "\n",
    "print(full_list)\n",
    "\n",
    "domain = 'example.com'\n",
    "for link in full_list:\n",
    "    if domain in link:\n",
    "        print(f\"{link} : {domain}이 포함됨\")\n",
    "    else:\n",
    "        print(f\"{link} : {domain}이 포함하지 않음\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "45a6821d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['순위', '이름', '점수', '등급']\n",
      "[[1, '김철수', 95, 'A+'], [2, '이영희', 88, 'B+']]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>순위</th>\n",
       "      <th>이름</th>\n",
       "      <th>점수</th>\n",
       "      <th>등급</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>김철수</td>\n",
       "      <td>95</td>\n",
       "      <td>A+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>이영희</td>\n",
       "      <td>88</td>\n",
       "      <td>B+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   순위   이름  점수  등급\n",
       "0   1  김철수  95  A+\n",
       "1   2  이영희  88  B+"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "url = \"http://ssacademy.dothome.co.kr/02.html\"\n",
    "\n",
    "response = requests.get(url)\n",
    "response.encoding = 'utf-8'\n",
    "html = response.text\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "table = soup.select_one('table.data-table')\n",
    "column = [ th.text.strip() for th in soup.select('thead th')]\n",
    "\n",
    "data = []\n",
    "rows = soup.select(\"tbody tr.student-row\")\n",
    "for row in rows:\n",
    "    data.append([int(td.text) if td.text.isdigit() else td.text for td in row.select('td')])\n",
    "\n",
    "# print(trs)\n",
    "print(column)\n",
    "print(data)\n",
    "\n",
    "df = pd.DataFrame(data, columns = column)\n",
    "# df.info()\n",
    "df.to_csv(\"student_score.csv\", index = False, encoding = 'utf-8')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcfaff91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['순위', '이름', '점수', '등급']\n",
      "[[1, '김철수', 95, 'A+'], [2, '이영희', 88, 'B+']]\n"
     ]
    }
   ],
   "source": [
    "# DB에 값 넣기\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import sqlite3\n",
    "\n",
    "url = \"http://ssacademy.dothome.co.kr/02.html\"\n",
    "\n",
    "response = requests.get(url)\n",
    "response.encoding = 'utf-8'\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "columns = []\n",
    "for th in soup.select(\"thead th\"):\n",
    "    columns.append(th.text)\n",
    "\n",
    "data = []\n",
    "rows = soup.select(\"tbody tr.student-row\")\n",
    "for row in rows:\n",
    "    \n",
    "    row_data = []\n",
    "    for td in row.select(\"td\"):\n",
    "        row_data.append(int(td.text) if td.text.isdigit() else td.text)\n",
    "    \n",
    "    data.append(row_data)\n",
    "\n",
    "conn = sqlite3.connect('student_scores.db')\n",
    "\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS StudentScores (\n",
    "    Rank INTEGER,\n",
    "    Name TEXT,\n",
    "    Score INTEGER,\n",
    "    Grade TEXT\n",
    ");\n",
    "\"\"\"\n",
    "conn.execute(create_table_query)\n",
    "\n",
    "insert_query = \"INSERT INTO StudentScores (Rank, Name, Score, Grade) VALUES (?, ?, ?, ?)\"\n",
    "# conn.executemany(insert_query, data)\n",
    "for row in data:\n",
    "    conn.execute(insert_query, row)\n",
    "\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "print(columns)\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9b9256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "과학\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'username': 'test_user',\n",
       " 'email': 'test@example.com',\n",
       " 'interests': 'science',\n",
       " 'subscribe': True}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"http://ssacademy.dothome.co.kr/03.html\"\n",
    "\n",
    "response = requests.get(url)\n",
    "response.encoding = 'utf-8'\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "form_data = {}\n",
    "\n",
    "inputs = soup.select('input[type = \"text\"], input[type = \"email\"]')\n",
    "for input in inputs:\n",
    "    # print(input['value'])\n",
    "    value = input.get('value','')\n",
    "    form_data[input['name']] = value\n",
    "\n",
    "select_opt = soup.select_one('select > option[selected]')\n",
    "# select_opt['value']\n",
    "select_opt_value = select_opt.get('value','')\n",
    "print(select_opt.text)\n",
    "select_ele = select_opt.find_parent('select')\n",
    "form_data[select_ele['name']] = select_opt_value\n",
    "\n",
    "checkbox = soup.select_one(\"input[type = 'checkbox']\")\n",
    "checked = checkbox.has_attr('checked')\n",
    "form_data[checkbox['name']] = checked\n",
    "\n",
    "form_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b55b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fruits': ['바나나', '체리']}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"http://ssacademy.dothome.co.kr/04.html\"\n",
    "\n",
    "response = requests.get(url)\n",
    "response.encoding = 'utf-8'\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "select_opts = soup.select('select > option[selected]')\n",
    "\n",
    "if select_opts:\n",
    "    select_ele = select_opts[0].find_parent('select')\n",
    "    form_data2 = {select_ele['name'] : []}\n",
    "    for select_opt in select_opts:\n",
    "        # if select_ele['name'] in form_data2:\n",
    "        #     form_data2[select_ele['name']].append(select_opt.text)\n",
    "        # else:\n",
    "        #     form_data2[select_ele['name']] = []\n",
    "        #     form_data2[select_ele['name']].append(select_opt.text)\n",
    "        form_data2[select_ele['name']].append(select_opt.text)\n",
    "else:\n",
    "    print(\"선택된 값이 없습니다\")\n",
    "form_data2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d4047af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 1, 'src': 'image1.png', 'alt': '첫 번째 이미지', 'title': '아름다운 풍경', 'photographer': '김작가'}, {'id': 2, 'src': 'image2.png', 'alt': '두 번째 이미지', 'title': '도시의, 밤', 'photographer': '이작가'}]\n"
     ]
    }
   ],
   "source": [
    "# [\n",
    "# {'id': 1, 'src': 'image1.png', 'alt': '첫 번째 이미지', 'title': '아름다운 풍경', 'photographer': '김작가'}, \n",
    "# {'id': 2, 'src': 'image2.png', 'alt': '두 번째 이미지', 'title': '도시의, 밤', 'photographer': '이작가'}\n",
    "#]\n",
    "\n",
    "# 이미지는 img폴더에 저장\n",
    "# 메타데이터는 DB로 저장\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import os\n",
    "import sqlite3\n",
    "\n",
    "url = \"http://ssacademy.dothome.co.kr/05.html\"\n",
    "\n",
    "response = requests.get(url)\n",
    "response.encoding = 'utf-8'\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "images = []\n",
    "\n",
    "for container in soup.select('div.image-container'):\n",
    "    img = container.select_one('img')\n",
    "    info = container.select_one('.image-info')\n",
    "\n",
    "    image_data = {\n",
    "        'id': int(img['data-id']),\n",
    "        'src': img['src'],\n",
    "        'alt': img['alt'],\n",
    "        'title': info.select_one(\".title\").text,\n",
    "        'photographer': info.select_one(\".photographer\").text.split(\": \")[-1]\n",
    "    }\n",
    "\n",
    "    images.append(image_data)\n",
    "\n",
    "print(images)\n",
    "\n",
    "\n",
    "conn = sqlite3.connect('images.db')\n",
    "cursor = conn.cursor()\n",
    "cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS images (\n",
    "        id INTEGER PRIMARY KEY,\n",
    "        src TEXT,\n",
    "        alt TEXT,\n",
    "        title TEXT,\n",
    "        photographer TEXT\n",
    "    )\n",
    "''')\n",
    "conn.commit()\n",
    "\n",
    "\n",
    "os.makedirs('img', exist_ok=True)  \n",
    "\n",
    "for image in images:\n",
    "    image_url = urljoin(url, image['src'])\n",
    "    save_path = \"img/\" + image['src']\n",
    "    response = requests.get(image_url)\n",
    "    if response.status_code == 200:\n",
    "        with open(save_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        cursor.execute('''\n",
    "            INSERT INTO images (id, src, alt, title, photographer)\n",
    "            VALUES (?, ?, ?, ?, ?)\n",
    "        ''', (image['id'], image['src'], image['alt'], image['title'], image['photographer']))\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0bebb5e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': '블로그 제목 1',\n",
       "  'date': '2024-01-01',\n",
       "  'author': '김블로그',\n",
       "  'data-userid': 'user123',\n",
       "  'content': '첫 번째 블로그 내용입니다...\\n추가 내용...',\n",
       "  'tags': ['#python', '#coding']},\n",
       " {'title': '블로그 제목 2',\n",
       "  'date': '2024-01-03',\n",
       "  'author': '이블로그',\n",
       "  'data-userid': 'user456',\n",
       "  'content': '오늘 엄청나게 추워요\\n손도 시렵고 발도 시렵고 귀도 시려워요\\n모두 힘내요!',\n",
       "  'tags': ['#crawling', '#coding']},\n",
       " {'title': '블로그 제목 3',\n",
       "  'date': '2025-08-03',\n",
       "  'author': '박블로그',\n",
       "  'data-userid': 'user789',\n",
       "  'content': '오늘 너무 덥네요\\n교실이 최고!!! 나가지 맙시다~~~\\n모두 힘내요!',\n",
       "  'tags': ['#ai', '#project']}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "url = \"http://ssacademy.dothome.co.kr/06.html\"\n",
    "\n",
    "html = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(html.text,'html.parser')\n",
    "\n",
    "articles = soup.select('article.post-wrapper')\n",
    "\n",
    "blogs = []\n",
    "\n",
    "for article in articles:\n",
    "    # 굵은 클래스 가져오기\n",
    "    header = article.select_one('div.post-header')\n",
    "    content = article.select_one('div.content')\n",
    "    tags = article.select_one('ul.tags')\n",
    "\n",
    "    # 필요한 태그의 클래스명(키값) 가져오기\n",
    "    title_key = header.select_one('h1.title')['class'][0]\n",
    "    date_key = header.select_one('span.date')['class'][0]\n",
    "    author_key = header.select_one('div.author')['class'][0]\n",
    "    uid_key = 'data-userid'\n",
    "    content_key = content['class'][0]\n",
    "    tags_key = tags['class'][0]\n",
    "\n",
    "    # 가져온 키값들을 리스트로 저장\n",
    "    keys = [title_key, date_key, author_key, uid_key, content_key, tags_key]\n",
    "    # print(keys)\n",
    "\n",
    "    # 필요한 태그의 값 가져오기\n",
    "    title = header.select_one('h1.title').text\n",
    "    date = header.select_one('span.date').text\n",
    "    author = header.select_one('div.author').text.split(':')[-1].strip()\n",
    "    uid = header.select_one('div.author')['data-userid']\n",
    "    content = content.text.strip()\n",
    "    tag_list = [tag.text for tag in tags.select('li')]\n",
    "\n",
    "    # 값들을 리스트로 저장\n",
    "    values = [title, date, author, uid, content, tag_list]\n",
    "    # print(values)\n",
    "\n",
    "    # 키와 값을 딕셔너리로 변환해 리스트에 저장\n",
    "    blogs.append(dict(zip(keys,values)))\n",
    "\n",
    "blogs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
